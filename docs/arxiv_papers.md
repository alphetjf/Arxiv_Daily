# Arxiv Papers

| 标题  | 摘要 | 作者 | PDF链接 | 代码仓库 | Title | Abstract | 
|-------|---------|----------|-----------|------------------|--------------------|---------|
| 使用基于SAM2的跟踪进行在线轴估计的铰接物体操作 | 铰接物体操作需要精确的物体交互，其中物体的轴必须仔细考虑。先前的研究采用了交互感知来操作铰接物体，但通常开环方法往往忽视了交互动力学。为了解决这一局限性，我们提出了一种闭环管道，将交互感知与从分割的3D点云中在线轴估计相结合。我们的方法利用任何交互感知技术作为基础，通过引发轻微的物体移动来生成动态场景的点云帧。然后使用Segment Anything Model 2（SAM2）对这些点云进行分割，之后对物体的移动部分进行掩码处理，以进行精确的在线轴估计，指导后续的机器人动作。我们的方法显著提高了涉及铰接物体的操作任务的精度和效率。在模拟环境中的实验表明，我们的方法优于基线方法，特别是在需要精确轴控制的任务中。项目页面：https://hytidel.github.io/video-tracking-for-axis-estimation/。 | Xi Wang | [PDF](http://arxiv.org/pdf/2409.16287v1) | N/A | Articulated Object Manipulation using Online Axis Estimation with SAM2-Based Tracking | Articulated object manipulation requires precise object interaction, where the object's axis must be carefully considered. Previous research employed interactive perception for manipulating articulated objects, but typically, open-loop approaches often suffer from overlooking the interaction dynamics. To address this limitation, we present a closed-loop pipeline integrating interactive perception with online axis estimation from segmented 3D point clouds. Our method leverages any interactive perception technique as a foundation for interactive perception, inducing slight object movement to generate point cloud frames of the evolving dynamic scene. These point clouds are then segmented using Segment Anything Model 2 (SAM2), after which the moving part of the object is masked for accurate motion online axis estimation, guiding subsequent robotic actions. Our approach significantly enhances the precision and efficiency of manipulation tasks involving articulated objects. Experiments in simulated environments demonstrate that our method outperforms baseline approaches, especially in tasks that demand precise axis-based control. Project Page: https://hytidel.github.io/video-tracking-for-axis-estimation/. |
| Gen2Act：新颖场景中的人类视频生成助力可泛化的机器人操作 | 机器人操作策略如何推广到涉及未见过的物体类型和新动作的新任务？在本文中，我们提出了一种解决方案，即通过人类视频生成从网络数据中预测运动信息，并将机器人策略条件化于生成的视频。我们没有尝试扩展昂贵的机器人数据收集，而是展示了如何利用在易获取的网络数据上训练的视频生成模型来实现泛化。我们的方法Gen2Act将语言条件化的操作视为零样本的人类视频生成，随后通过一个以生成视频为条件的单一策略进行执行。为了训练该策略，我们使用的机器人交互数据量比视频预测模型训练时使用的数据量少一个数量级。Gen2Act完全不需要微调视频模型，我们直接使用预训练模型来生成人类视频。我们在多样化的现实场景中的结果展示了Gen2Act如何实现对未见过的物体类型的操作，并执行机器人数据中不存在的新任务的新动作。视频演示请访问：https://homangab.github.io/gen2act/ | Homanga Bharadhwaj | [PDF](http://arxiv.org/pdf/2409.16283v1) | N/A | Gen2Act: Human Video Generation in Novel Scenarios enables Generalizable Robot Manipulation | How can robot manipulation policies generalize to novel tasks involving unseen object types and new motions? In this paper, we provide a solution in terms of predicting motion information from web data through human video generation and conditioning a robot policy on the generated video. Instead of attempting to scale robot data collection which is expensive, we show how we can leverage video generation models trained on easily available web data, for enabling generalization. Our approach Gen2Act casts language-conditioned manipulation as zero-shot human video generation followed by execution with a single policy conditioned on the generated video. To train the policy, we use an order of magnitude less robot interaction data compared to what the video prediction model was trained on. Gen2Act doesn't require fine-tuning the video model at all and we directly use a pre-trained model for generating human videos. Our results on diverse real-world scenarios show how Gen2Act enables manipulating unseen object types and performing novel motions for tasks not present in the robot data. Videos are at https://homangab.github.io/gen2act/ |
| 学习帮助：训练模型以辅助传统设备 | 在物理设备上通过硬件实现的机器学习模型可能会被长期部署。设备的计算能力可能有限，并且随着新技术的改进而变得过时。由于机器学习模型的大小，将部分计算任务（例如，转移到边缘云）可以帮助这些老旧设备。我们将这个问题置于带弃权的学习的框架中（LWA），其中专家（边缘）必须经过训练以协助客户端（设备）。先前关于LWA的工作假设边缘是一个预言机或人类专家，并训练客户端。在这项工作中，我们形式化了相反的问题，即训练专家以适应固定的（老旧的）客户端。与LWA一样，客户端使用拒绝规则来决定何时将推理任务卸载给专家（需付出成本）。我们找到了贝叶斯最优规则，证明了泛化边界，并找到了一致的替代损失函数。实证结果表明，我们的框架优于基于置信度的拒绝规则。 | Yu Wu | [PDF](http://arxiv.org/pdf/2409.16253v1) | N/A | Learning To Help: Training Models to Assist Legacy Devices | Machine learning models implemented in hardware on physical devices may be deployed for a long time. The computational abilities of the device may be limited and become outdated with respect to newer improvements. Because of the size of ML models, offloading some computation (e.g. to an edge cloud) can help such legacy devices. We cast this problem in the framework of learning with abstention (LWA) in which the expert (edge) must be trained to assist the client (device). Prior work on LWA trains the client assuming the edge is either an oracle or a human expert. In this work, we formalize the reverse problem of training the expert for a fixed (legacy) client. As in LWA, the client uses a rejection rule to decide when to offload inference to the expert (at a cost). We find the Bayes-optimal rule, prove a generalization bound, and find a consistent surrogate loss function. Empirical results show that our framework outperforms confidence-based rejection rules. |
| 世界田地：全球农业田地边界分割的机器学习基准数据集 | 农田边界是农业监测和评估的基础数据集，但手动采集成本高昂。机器学习（ML）方法能够自动从遥感图像中提取农田边界，有助于在全球范围内满足这些数据集的需求。然而，当前用于农田实例分割的ML方法在地理覆盖范围、准确性和泛化能力方面存在不足。此外，由于缺乏代表全球农田多样性的标注数据集，改进ML方法的研究受到限制。我们提出了“世界农田”（Fields of The World, FTW）——一个涵盖四大洲（欧洲、非洲、亚洲和南美洲）24个国家的农业农田实例分割的新型ML基准数据集。FTW的数据规模是之前数据集的十倍，包含70,462个样本，每个样本都包含实例和语义分割掩码，并与多日期、多光谱的Sentinel-2卫星图像配对。我们提供了新FTW基准的基线模型结果，表明在未见过的国家中，使用FTW训练的模型在零样本和微调性能上优于未经过多样化数据预训练的模型，并在实际场景中展示了FTW模型在埃塞俄比亚Sentinel-2图像上的积极零样本定性结果。 | Hannah Kerner | [PDF](http://arxiv.org/pdf/2409.16252v1) | N/A | Fields of The World: A Machine Learning Benchmark Dataset For Global Agricultural Field Boundary Segmentation | Crop field boundaries are foundational datasets for agricultural monitoring and assessments but are expensive to collect manually. Machine learning (ML) methods for automatically extracting field boundaries from remotely sensed images could help realize the demand for these datasets at a global scale. However, current ML methods for field instance segmentation lack sufficient geographic coverage, accuracy, and generalization capabilities. Further, research on improving ML methods is restricted by the lack of labeled datasets representing the diversity of global agricultural fields. We present Fields of The World (FTW) -- a novel ML benchmark dataset for agricultural field instance segmentation spanning 24 countries on four continents (Europe, Africa, Asia, and South America). FTW is an order of magnitude larger than previous datasets with 70,462 samples, each containing instance and semantic segmentation masks paired with multi-date, multi-spectral Sentinel-2 satellite images. We provide results from baseline models for the new FTW benchmark, show that models trained on FTW have better zero-shot and fine-tuning performance in held-out countries than models that aren't pre-trained with diverse datasets, and show positive qualitative zero-shot results of FTW models in a real-world scenario -- running on Sentinel-2 scenes over Ethiopia. |
| LLM回音室：个性化与自动化的虚假信息传播 | 最近的进展展示了大型语言模型如GPT4和Llama2在摘要、翻译和内容审查等任务中的能力。然而，它们的广泛使用引发了担忧，特别是关于LLMs可能大规模传播具有说服力、类似人类的错误信息，这可能会显著影响公众舆论。本研究探讨了这些风险，重点关注LLMs传播错误信息作为事实的能力。为了研究这一点，我们构建了LLM回音室，一个模拟社交媒体聊天室的受控数字环境，错误信息常常在其中传播。回音室，即个体只与志同道合的人互动，进一步加深了信念。通过研究恶意机器人在这个环境中传播错误信息，我们可以更好地理解这一现象。我们回顾了当前的LLMs，探讨了错误信息的风险，并应用了最先进的微调技术。使用微软的phi2模型，通过我们的自定义数据集进行微调，我们生成了有害内容以创建回音室。这一设置通过GPT4评估其说服力和有害性，揭示了围绕LLMs的伦理问题，并强调了需要更强的防护措施来对抗错误信息。 | Tony Ma | [PDF](http://arxiv.org/pdf/2409.16241v1) | N/A | LLM Echo Chamber: personalized and automated disinformation | Recent advancements have showcased the capabilities of Large Language Models like GPT4 and Llama2 in tasks such as summarization, translation, and content review. However, their widespread use raises concerns, particularly around the potential for LLMs to spread persuasive, humanlike misinformation at scale, which could significantly influence public opinion. This study examines these risks, focusing on LLMs ability to propagate misinformation as factual. To investigate this, we built the LLM Echo Chamber, a controlled digital environment simulating social media chatrooms, where misinformation often spreads. Echo chambers, where individuals only interact with like minded people, further entrench beliefs. By studying malicious bots spreading misinformation in this environment, we can better understand this phenomenon. We reviewed current LLMs, explored misinformation risks, and applied sota finetuning techniques. Using Microsoft phi2 model, finetuned with our custom dataset, we generated harmful content to create the Echo Chamber. This setup, evaluated by GPT4 for persuasiveness and harmfulness, sheds light on the ethical concerns surrounding LLMs and emphasizes the need for stronger safeguards against misinformation. |
| 标签增强的数据集蒸馏 | 传统数据集蒸馏主要关注图像表示，而往往忽视标签的重要作用。在本研究中，我们引入了标签增强数据集蒸馏（Label-Augmented Dataset Distillation, LADD），这是一种通过标签增强来提升数据集蒸馏效果的新框架。LADD对每个合成图像进行子采样，生成额外的密集标签以捕捉丰富的语义信息。这些密集标签仅需增加2.5%的存储空间（针对ImageNet子集），却能带来显著的性能提升，提供强大的学习信号。我们的标签生成策略能够补充现有的数据集蒸馏方法，显著提升其训练效率和性能。实验结果表明，LADD在计算开销和准确性方面均优于现有方法。通过结合三种高性能的数据集蒸馏算法，LADD在准确性上实现了平均14.9%的显著提升。此外，我们的方法在多种数据集、蒸馏超参数和算法中均证明了其有效性。最后，我们的方法增强了蒸馏数据集在不同架构间的鲁棒性，这对于实际应用场景至关重要。 | Seoungyoon Kang | [PDF](http://arxiv.org/pdf/2409.16239v1) | N/A | Label-Augmented Dataset Distillation | Traditional dataset distillation primarily focuses on image representation while often overlooking the important role of labels. In this study, we introduce Label-Augmented Dataset Distillation (LADD), a new dataset distillation framework enhancing dataset distillation with label augmentations. LADD sub-samples each synthetic image, generating additional dense labels to capture rich semantics. These dense labels require only a 2.5% increase in storage (ImageNet subsets) with significant performance benefits, providing strong learning signals. Our label generation strategy can complement existing dataset distillation methods for significantly enhancing their training efficiency and performance. Experimental results demonstrate that LADD outperforms existing methods in terms of computational overhead and accuracy. With three high-performance dataset distillation algorithms, LADD achieves remarkable gains by an average of 14.9% in accuracy. Furthermore, the effectiveness of our method is proven across various datasets, distillation hyperparameters, and algorithms. Finally, our method improves the cross-architecture robustness of the distilled dataset, which is important in the application scenario. |
| 通过廉价地排序挖掘的规则，高效地学习概率逻辑模型 | 概率逻辑模型是神经符号人工智能的核心组成部分，对于需要高度可解释性的任务而言，它们本身就是重要的模型。与神经网络不同，逻辑模型通常使用领域专业知识手工构建，这使得其开发成本高昂且容易出错。尽管存在从数据中学习逻辑模型的算法，但它们通常成本过高，限制了其在现实世界中的应用。在这项工作中，我们为逻辑规则引入了精确度和召回率，并将它们的组合定义为规则效用——一种成本效益高的度量方法，用于评估逻辑模型的预测能力。此外，我们引入了SPECTRUM，这是一个可扩展的框架，用于从关系数据中学习逻辑模型。其可扩展性源于一种线性时间算法，该算法挖掘数据中的重复结构，以及另一种使用廉价效用度量的算法，该算法高效地对基于这些结构构建的规则进行排序。此外，我们为所学逻辑模型的效用提供了理论保证。因此，SPECTRUM在真实世界数据集上比以往的方法快几个数量级地学习到更准确的逻辑模型。 | Jonathan Feldstein | [PDF](http://arxiv.org/pdf/2409.16238v1) | N/A | Efficiently Learning Probabilistic Logical Models by Cheaply Ranking Mined Rules | Probabilistic logical models are a core component of neurosymbolic AI and are important models in their own right for tasks that require high explainability. Unlike neural networks, logical models are often handcrafted using domain expertise, making their development costly and prone to errors. While there are algorithms that learn logical models from data, they are generally prohibitively expensive, limiting their applicability in real-world settings. In this work, we introduce precision and recall for logical rules and define their composition as rule utility -- a cost-effective measure to evaluate the predictive power of logical models. Further, we introduce SPECTRUM, a scalable framework for learning logical models from relational data. Its scalability derives from a linear-time algorithm that mines recurrent structures in the data along with a second algorithm that, using the cheap utility measure, efficiently ranks rules built from these structures. Moreover, we derive theoretical guarantees on the utility of the learnt logical model. As a result, SPECTRUM learns more accurate logical models orders of magnitude faster than previous methods on real-world datasets. |
| 使用生存变换器、极端梯度提升和Cox比例风险模型预测轻度认知障碍的恶化 | 本文提出了一种利用ADNI队列中的代谢组学数据，预测轻度认知障碍（MCI）个体认知衰退的新方法，即生存变换器和极端梯度提升模型。通过利用应用于生存分析的先进机器学习和基于变换器的技术，所提出的方法突显了这些技术在更准确地早期检测和干预阿尔茨海默病性痴呆方面的潜力。这项研究还强调了非侵入性生物标志物和创新建模工具在提高痴呆风险评估准确性方面的重要性，为临床实践和患者护理提供了新的途径。一个包含100次嵌套交叉验证重复的全面蒙特卡罗模拟过程表明，基于变换器和XGBoost的生存机器学习模型分别达到了最高的平均C-index表现，分别为0.85和0.8，并且优于传统的生存分析Cox比例风险模型，后者达到了0.77的平均C-index。此外，基于蒙特卡罗模拟中获得的C-index表现的标 | Henry Musto | [PDF](http://arxiv.org/pdf/2409.16231v1) | N/A | Predicting Deterioration in Mild Cognitive Impairment with Survival Transformers, Extreme Gradient Boosting and Cox Proportional Hazard Modelling | The paper proposes a novel approach of survival transformers and extreme gradient boosting models in predicting cognitive deterioration in individuals with mild cognitive impairment (MCI) using metabolomics data in the ADNI cohort. By leveraging advanced machine learning and transformer-based techniques applied in survival analysis, the proposed approach highlights the potential of these techniques for more accurate early detection and intervention in Alzheimer's dementia disease. This research also underscores the importance of non-invasive biomarkers and innovative modelling tools in enhancing the accuracy of dementia risk assessments, offering new avenues for clinical practice and patient care. A comprehensive Monte Carlo simulation procedure consisting of 100 repetitions of a nested cross-validation in which models were trained and evaluated, indicates that the survival machine learning models based on Transformer and XGBoost achieved the highest mean C-index performances, namely 0.85 and 0.8, respectively, and that they are superior to the conventional survival analysis Cox Proportional Hazards model which achieved a mean C-Index of 0.77. Moreover, based on the standard deviations of the C-Index performances obtained in the Monte Carlo simulation, we established that both survival machine learning models above are more stable than the conventional statistical model. |
| 微调是可行的，只要经过校准 | 微调无疑是将预训练模型（例如基础模型）定制到下游应用的最直接方法，但它也伴随着丢失模型在预训练中获得的有价值知识的潜在风险。例如，将一个能够识别大量类别的预训练分类器微调为掌握当前子集中的类别，已被证明会大幅降低模型在其他先前学习类别中的准确性。因此，当微调后的模型遇到超出微调数据范围的类别时，很难进一步使用它。在本文中，我们系统地剖析了这一问题，旨在回答一个基本问题：“微调后的模型中究竟损失了什么？”令我们惊讶的是，我们发现微调后的模型既没有忘记其他类别之间的关系，也没有降低识别这些类别的特征。相反，微调后的模型通常会为这些其他类别生成更具区分性的特征，即使这些类别在微调过程中缺失！真正损害准确性的是微调类别与其他类别之间不一致的logit尺度，这意味着简单的后处理校准不仅可以恢复预训练模型的能力，还能同时揭示所有类别特征的改进。我们进行了广泛的实证研究，以展示我们发现的鲁棒性，并提供了初步的解释，指出了未来理论分析的新方向。我们的代码可在https://github.com/OSU-MLB/Fine-Tuning-Is-Fine-If-Calibrated获取。 | Zheda Mai | [PDF](http://arxiv.org/pdf/2409.16223v1) | N/A | Fine-Tuning is Fine, if Calibrated | Fine-tuning is arguably the most straightforward way to tailor a pre-trained model (e.g., a foundation model) to downstream applications, but it also comes with the risk of losing valuable knowledge the model had learned in pre-training. For example, fine-tuning a pre-trained classifier capable of recognizing a large number of classes to master a subset of classes at hand is shown to drastically degrade the model's accuracy in the other classes it had previously learned. As such, it is hard to further use the fine-tuned model when it encounters classes beyond the fine-tuning data. In this paper, we systematically dissect the issue, aiming to answer the fundamental question, ''What has been damaged in the fine-tuned model?'' To our surprise, we find that the fine-tuned model neither forgets the relationship among the other classes nor degrades the features to recognize these classes. Instead, the fine-tuned model often produces more discriminative features for these other classes, even if they were missing during fine-tuning! {What really hurts the accuracy is the discrepant logit scales between the fine-tuning classes and the other classes}, implying that a simple post-processing calibration would bring back the pre-trained model's capability and at the same time unveil the feature improvement over all classes. We conduct an extensive empirical study to demonstrate the robustness of our findings and provide preliminary explanations underlying them, suggesting new directions for future theoretical analysis. Our code is available at https://github.com/OSU-MLB/Fine-Tuning-Is-Fine-If-Calibrated. |
| 利用大型语言模型提升对话式用户界面中的关联数据检索 | 尽管大型语言模型（LLMs）在各个领域得到了广泛应用，但其在丰富信息系统、提取和探索关联数据（LD）以及资源描述框架（RDF）三元组存储方面的潜力尚未得到充分探索。本文探讨了将LLMs集成到现有系统中，重点在于增强对话用户界面（UIs）及其通过生成更准确的SPARQL查询进行数据提取的能力，而无需重新训练模型。通常，对话UI模型在引入新数据集或更新时需要重新训练，限制了其作为通用提取工具的功能。我们的方法通过将LLMs融入对话UI工作流程，显著提升了其理解和有效处理用户查询的能力。通过利用LLMs先进的自然语言理解能力，我们的方法改进了在采用传统聊天机器人的网络系统中的RDF实体提取。这种集成促进了更加细致和上下文感知的交互模型，这对于处理RDF数据集和关联开放数据（LOD）端点中常见的复杂查询模式至关重要。对这种方法的评估显示，系统表达能力和用户查询响应的准确性显著提升，表明这一领域未来研究具有广阔前景。这项研究不仅突显了LLMs在增强现有信息系统方面的多功能性，还为进一步探索其在网络信息系统更专业化领域的潜在应用奠定了基础。 | Omar Mussa | [PDF](http://arxiv.org/pdf/2409.16220v1) | N/A | Towards Enhancing Linked Data Retrieval in Conversational UIs using Large Language Models | Despite the recent broad adoption of Large Language Models (LLMs) across various domains, their potential for enriching information systems in extracting and exploring Linked Data (LD) and Resource Description Framework (RDF) triplestores has not been extensively explored. This paper examines the integration of LLMs within existing systems, emphasising the enhancement of conversational user interfaces (UIs) and their capabilities for data extraction by producing more accurate SPARQL queries without the requirement for model retraining. Typically, conversational UI models necessitate retraining with the introduction of new datasets or updates, limiting their functionality as general-purpose extraction tools. Our approach addresses this limitation by incorporating LLMs into the conversational UI workflow, significantly enhancing their ability to comprehend and process user queries effectively. By leveraging the advanced natural language understanding capabilities of LLMs, our method improves RDF entity extraction within web systems employing conventional chatbots. This integration facilitates a more nuanced and context-aware interaction model, critical for handling the complex query patterns often encountered in RDF datasets and Linked Open Data (LOD) endpoints. The evaluation of this methodology shows a marked enhancement in system expressivity and the accuracy of responses to user queries, indicating a promising direction for future research in this area. This investigation not only underscores the versatility of LLMs in enhancing existing information systems but also sets the stage for further explorations into their potential applications within more specialised domains of web information systems. |
